{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeagrTavakol/Final_dataminning/blob/main/Copy_of_Final_projet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5ubuf-7Mqwp"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Zsf-6dW0BB",
        "outputId": "3a6fcb95-df50-4bcc-9f18-d78e4063e6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x78584ISF7M3"
      },
      "source": [
        "**Read dev dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXQhl0FxNEXe"
      },
      "outputs": [],
      "source": [
        "dev_csv=\"/content/drive/MyDrive/Colab Notebooks/dev.csv\"\n",
        "dev_df = pd.read_csv(dev_csv,sep='\\t')\n",
        "dev_df=dev_df.drop(\"Unnamed: 0\",axis=1)\n",
        "dev_columns=dev_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV2uRteWF-f2"
      },
      "source": [
        "**Read train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlwRTZ4CNN75"
      },
      "outputs": [],
      "source": [
        "train_csv=\"/content/drive/MyDrive/Colab Notebooks/train.csv\"\n",
        "train_df = pd.read_csv(train_csv,sep='\\t')\n",
        "train_df=train_df.drop(\"Unnamed: 0\",axis=1)\n",
        "train_columns = train_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KwhovBfPXyj"
      },
      "source": [
        "# **Tokenize Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRs4-6bMGCPl"
      },
      "source": [
        "**install packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LZoqDbvPgP6",
        "outputId": "7c962431-2a88-4c7f-ac4d-89c25a6a2395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[K     |████████████████████████████████| 432 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=6d5c6c0a624737ebfe540d7a55f32c3bbe8cab15cecc1390d2db46787eca7c26\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.6.3 stanza-1.3.0\n"
          ]
        }
      ],
      "source": [
        "# Install; note that the prefix \"!\" is not needed if you are running in a terminal\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPZpcwI5rdgN"
      },
      "outputs": [],
      "source": [
        "# Import the package\n",
        "import stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "C3xfPJpVQO8o",
        "outputId": "41cce07c-7848-45d8-9605-d0f4f0e102f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Persian model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37fdfd3235db4628bb47bd9da2d14461",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-28 16:48:11 INFO: Downloading default packages for language: fa (Persian)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c1b3c82a4264bac8f8eabe75e4f3a2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-fa/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-28 16:48:19 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ],
      "source": [
        "# Download an Persiabn model into the default directory\n",
        "print(\"Downloading Persian model...\")\n",
        "stanza.download('fa')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KFpju0aGG6B"
      },
      "source": [
        "**create models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKIL-W1CQjEB",
        "outputId": "7538754c-2905-44c5-bcdd-43a5c088eec3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-28 16:48:22 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "| lemma     | perdt   |\n",
            "| depparse  | perdt   |\n",
            "=======================\n",
            "\n",
            "2022-01-28 16:48:22 INFO: Use device: gpu\n",
            "2022-01-28 16:48:22 INFO: Loading: tokenize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building a Persian pipeline...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-28 16:48:35 INFO: Loading: mwt\n",
            "2022-01-28 16:48:35 INFO: Loading: pos\n",
            "2022-01-28 16:48:35 INFO: Loading: lemma\n",
            "2022-01-28 16:48:35 INFO: Loading: depparse\n",
            "2022-01-28 16:48:36 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "# Build a Persian pipeline, with all processors by default\n",
        "print(\"Building a Persian pipeline...\")\n",
        "fa_nlp = stanza.Pipeline('fa')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvm7Rjb8GJDx"
      },
      "source": [
        "**find tokens of dataframe and save in array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPM0Kb_NURsi"
      },
      "outputs": [],
      "source": [
        "# test_token_df['tokenized_sents'] = test_token_df.apply(lambda row: fa_nlp(row['comment']).sentences.words.text, axis=1)\n",
        "tokenized_array=[]\n",
        "for i in range(0,len(train_df)[:52465]):\n",
        "  comment=train_df.iloc[i][\"comment\"]\n",
        "  tokenized_comment = fa_nlp(comment)\n",
        "  tokens_array=[]\n",
        "  for i,sent in enumerate(tokenized_comment.sentences):\n",
        "    for word in sent.words:\n",
        "      tokens_array.append(word.text)\n",
        "  tokenized_array.append(tokens_array)\n",
        "#word.text, word.lemma, word.pos, word.head, word.deprel))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoetAKhg7wRZ",
        "outputId": "4957b761-424b-4f4e-d99e-3dd0a5701d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n"
          ]
        }
      ],
      "source": [
        "#find tokens of rest of dataset (process interupted cause of volume of dataset)\n",
        "# rest_train_df=train_df[52466:]\n",
        "for i in range(52466,len(train_df)):\n",
        "  comment=train_df.iloc[i][\"comment\"]\n",
        "  tokenized_comment = fa_nlp(comment)\n",
        "  tokens_array=[]\n",
        "  for i,sent in enumerate(tokenized_comment.sentences):\n",
        "    for word in sent.words:\n",
        "      tokens_array.append(word.text)\n",
        "  tokenized_array.append(tokens_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OycN6D_LGYzb"
      },
      "source": [
        "**save tokens array to csv file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nndyXJXsA-lj"
      },
      "outputs": [],
      "source": [
        "#save tokens to array\n",
        "import csv\n",
        "with open('tokens_array.csv', 'w', newline='') as file:\n",
        "    mywriter = csv.writer(file, delimiter=',')\n",
        "    mywriter.writerows(tokenized_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXccrNvIGNte"
      },
      "source": [
        "**convert tokens array to dataframe **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDvkVouPdNF7"
      },
      "outputs": [],
      "source": [
        "# convert tokenized_array to dataframe\n",
        "tokenized_df=pd.DataFrame(tokenized_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpq4V7vUGZ-y"
      },
      "source": [
        "**save dataframe to csv file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMLslzyPGZHq"
      },
      "outputs": [],
      "source": [
        "#save dataframe \n",
        "tokenized_df.to_csv('tokens_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoyKXLy-EQ9H"
      },
      "outputs": [],
      "source": [
        "# with open('tokens_array.csv', 'r', newline='') as file:\n",
        "#   myreader = csv.reader(file, delimiter=',')\n",
        "#   for rows in myreader:\n",
        "#     print(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yej2YkqA2Eur"
      },
      "source": [
        "# **Read tokenized dataet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6fQbUzcTvX"
      },
      "source": [
        "**read from array csv file **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QWQlYVeHBPt"
      },
      "outputs": [],
      "source": [
        "#read array csv file\n",
        "tokens_array=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/tokens_array.csv\",sep='\\t',header=None)\n",
        "# tokens_array.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RMbt2gy2Cjd"
      },
      "source": [
        "# **Preproccessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVBLDgZsG9mx"
      },
      "source": [
        "**Remove punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO3oUTO7V2fW"
      },
      "outputs": [],
      "source": [
        "from types import new_class\n",
        "# from string import punctuation\n",
        "import re\n",
        "\n",
        "punctuation=['!','\"','#','$','%','&',\"'\",'(',')','*','+','،','-','.',','\"/\",':',';','<','=','>','?','@','[',\"\\\\\",\"]\",\"^\",'_','`','{','|','}','~']\n",
        "# tokens_array.to_numpy()\n",
        "tokens_arr=[]\n",
        "for i in tokens_array.to_numpy():\n",
        "  sent=[]\n",
        "  for j in i[0].split(','):\n",
        "    if j not in punctuation:\n",
        "      sent.append(j)\n",
        "  tokens_arr.append(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVOLFx-BsATM"
      },
      "source": [
        "**Analyze Reviews Length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmqpe1pxrrOg"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "reviews_len = [len(x) for x in tokens_arr]\n",
        "reviews_len=np.array(reviews_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXKuxOdGyRPx"
      },
      "outputs": [],
      "source": [
        "# pd.Series(tokens_arr).hist()\n",
        "# plt.show()\n",
        "# pd.Series(tokens_arr).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1POTybkdsYIc",
        "outputId": "2bb843a4-029a-430c-d044-2b4ec7032186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min: 3 max: 362 min: 19.003015873015872 len: 56700\n"
          ]
        }
      ],
      "source": [
        "print(\"min:\",reviews_len.min(),\"max:\",reviews_len.max(),\"min:\",reviews_len.mean(),\"len:\",len(reviews_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI_5SETMti6E",
        "outputId": "1ad4328f-4b3c-48d4-a57c-0c6515ce4943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "538\n"
          ]
        }
      ],
      "source": [
        "print(np.count_nonzero(reviews_len > 80))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdwzIqgukt-2"
      },
      "source": [
        "**Remove outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGdu_Vvt5RCb"
      },
      "outputs": [],
      "source": [
        "# cleaned_rokens_arr=[x for x in tokens_arr if len(x)<81]\n",
        "# print(len(cleaned_rokens_arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN_EyeBDRV3C"
      },
      "source": [
        "ثریا \n",
        "اینجا کد ورد امبدنیگ رو میتونی ببینی \n",
        "کلمات مختلفی هم باهاش امتحان کردم اوکی شد"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LELpzRA6Fd-j"
      },
      "source": [
        "# **Word embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0NNhnaCxdxP",
        "outputId": "b74f00e5-90d7-418c-857f-5411153df354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5y1iYU7HYaa"
      },
      "outputs": [],
      "source": [
        "#main_code\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Colab Notebooks/model.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Edv_CKUNQdhq"
      },
      "outputs": [],
      "source": [
        "vector = model['خوب']\n",
        "# see the shape of the vector (300,)\n",
        "# vector.shape\n",
        "list(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36AjZrxKQvcq"
      },
      "outputs": [],
      "source": [
        "# model.most_similar('بهتر')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRCDCwxkfqrl"
      },
      "source": [
        "**calculate vacors for each word**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUfd72WvbXuB",
        "outputId": "35f6313e-42b2-49ae-edc6-3a7db9fb9094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "vocabulary =model.wv.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI4Xf8LeeLMF",
        "outputId": "349eadad-aaab-421d-fb91-5b2403f66996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "966446 <class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "print(len(vocabulary),type(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFQ7oVEMHymP",
        "outputId": "f49b11fd-7dd0-4397-fc47-d61979b2c4b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "vectors_arr=[]\n",
        "for sent in tokens_arr:#cleaned_rokens_arr:\n",
        "  vec_vocab=[list(model[word]) for word in sent if word in model.wv.vocab]# if model[word]\n",
        "  vectors_arr.append(vec_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOyvPyu1BWXK",
        "outputId": "8a0ae3e8-279f-4e30-a547-174d7942acd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(vectors_arr[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9xrnLWqeqgZ",
        "outputId": "5312aec3-4fbf-48f4-a607-6ec1853abce8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "457360"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sys import getsizeof\n",
        "getsizeof(vectors_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKUfDhLtfyOP"
      },
      "source": [
        "**save embedded words in csv file(too large!)>500mb**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "272mlR6Uf7ID"
      },
      "outputs": [],
      "source": [
        "# #save vctors to array\n",
        "# import csv\n",
        "# with open('vectors_arr.csv', 'w', newline='') as file:\n",
        "#     mywriter = csv.writer(file, delimiter=',')\n",
        "#     mywriter.writerows(vectors_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8oE5RuA3tGi"
      },
      "outputs": [],
      "source": [
        "#to realease memory\n",
        "tokens_arr=[]\n",
        "tokens_array=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIGQ6GpIdOm"
      },
      "source": [
        "# **Prepare Train data for train**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt6Xp_H2yD7w"
      },
      "source": [
        "## **Vectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAFe4RyvJAEc"
      },
      "source": [
        "**lenght of vectors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4a6Nhdbu_mY"
      },
      "outputs": [],
      "source": [
        "vectors_arr[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CU21PMvJA4W"
      },
      "outputs": [],
      "source": [
        "vectors_len = [len(x) for x in vectors_arr]\n",
        "vectors=np.array(vectors_len)\n",
        "max_vector_len=max(vectors_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IonLx-JxtqX0",
        "outputId": "fa02c990-95aa-4e67-ac7b-2eeca9b3205e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "351"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_vector_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKrzKaYj4glL"
      },
      "outputs": [],
      "source": [
        "#to realease memory\n",
        "vectors_len=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4AiL_A8flt8"
      },
      "source": [
        "**Add padding to short comemnts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd9peTdEJDNa"
      },
      "outputs": [],
      "source": [
        "#add padding vetor 0\n",
        "padding_vec=[0.0]*100\n",
        "# padding_vec=np.array(padding_vec)\n",
        "pad_embedded_array=[]\n",
        "for vector in vectors_arr:\n",
        "  if len(vector)<max_vector_len:\n",
        "    padding=[padding_vec]*(max_vector_len-len(vector))\n",
        "    vector=vector+padding\n",
        "  pad_embedded_array.append(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jo4RI9cavk-y"
      },
      "outputs": [],
      "source": [
        "pad_embedded_array[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLTj__IoyGwc"
      },
      "source": [
        "## **Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMbeou2_ycXU"
      },
      "outputs": [],
      "source": [
        "l=train_df[\"label_id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdcqvNTV49zt"
      },
      "outputs": [],
      "source": [
        "#to release memory\n",
        "train_df=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqEwwNd9-c0b"
      },
      "source": [
        "# **Traingin LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMs2mRtE-jLl"
      },
      "source": [
        "**Import tensowerflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA6RlQ-O-cWy",
        "outputId": "d5514afb-3b5e-44d6-edbc-0688a9c8d7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFOXJkCERyEV"
      },
      "outputs": [],
      "source": [
        "SEED = 20\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STW4J4Z1RvBu"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duQzlsUJr235"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import Embedding\n",
        "from keras.layers import Input\n",
        "# from keras.layers import TimeDistributed, Bidirectional\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "# import tqdm\n",
        "# from tensorflow.keras import layers\n",
        "# from tensorflow.keras.preprocessing import sequence\n",
        "# from tensorflow.python.keras.layers import Input\n",
        "from keras.models import Sequential\n",
        "# from my_classes import DataGenerator\n",
        "# from keras.layers.embeddings import Embedding\n",
        "# from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CurworWsOQd9"
      },
      "outputs": [],
      "source": [
        "# import pathlib\n",
        "# import os\n",
        "# np.set_printoptions(precision=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUzPX6jrJpmw"
      },
      "source": [
        "**Create Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RyVWbYgs3WN",
        "outputId": "6ce809f9-c6e1-42a1-ad85-930802aa6ac6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9G7CEQTZXkH"
      },
      "outputs": [],
      "source": [
        "nb_samples = len(padding_vec)#55000\n",
        "time_steps=max_vector_len#74\n",
        "input_dim=100 #100\n",
        "input_shape=(time_steps,input_dim)\n",
        "n_epoch=1\n",
        "batch_size=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afQhD8HCtZzq",
        "outputId": "47bb5b74-ddc1-4508-c648-7ed20f735af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling the Model...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 351, 32)           17024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 351, 1)            33        \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 351, 1)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,057\n",
            "Trainable params: 17,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# create the model\n",
        "# embedding_weights = np.zeros((n_symbols, vocab_dim))\n",
        "lstm_model = Sequential()\n",
        "# model.add(LSTM(3NumberOfLSTM, return_sequences=True,input_shape=(YourSequenceLenght, YourWord2VecLenght)))\n",
        "lstm_model.add(LSTM(batch_size,return_sequences=True, input_shape=input_shape))\n",
        "# lstm_model.add(Dropout(0.2))\n",
        "# lstm_model.add(Dense(40, activation='softmax'))\n",
        "# lstm_model.add(Dense(20, activation='softmax'))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "lstm_model.add(Activation('sigmoid'))\n",
        "# lstm_model.add(Activation('softmax'))\n",
        "print('Compiling the Model...')\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRcPxuf4lQxR"
      },
      "outputs": [],
      "source": [
        "traingen = CustomDataGen(pad_embedded_array,y_col=l_train,batch_size=batch_size, input_size=5)\n",
        "# valgen = CustomDataGen(val_df,X_col={'path':'filename', 'bbox': 'region_shape_attributes'},\n",
        "                      #  y_col={'name': 'name', 'type': 'type'},batch_size=batch_siz, input_size=target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30hrhK6y95uS"
      },
      "outputs": [],
      "source": [
        "class CustomDataGen(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, df, y_col,\n",
        "                 batch_size,\n",
        "                 input_size,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.df = df#.copy()\n",
        "        # self.X_col = X_col\n",
        "        self.y_col = y_col\n",
        "        self.batch_size = batch_size\n",
        "        # self.input_size = input_size\n",
        "        self.shuffle = shuffle\n",
        "        self.n = len(self.df)\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        # batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        # X, y = self.__get_data(batches)  \n",
        "        print(type(self.y_col[index][0] ),type(self.df.iloc[index]))\n",
        "        X,y=self.df[index],self.y_col.iloc[index]      \n",
        "        print(x)\n",
        "        print(y)\n",
        "        return X, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n // self.batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlYKrzPJCmn0"
      },
      "outputs": [],
      "source": [
        "# train_df.fillna(value='', inplace=True)\n",
        "lstm_model.fit(traingen,epochs=n_epoch,verbose=1)#,callbacks=[es, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdSEijH1e7Xg"
      },
      "outputs": [],
      "source": [
        "numeric_dataset = tf.data.Dataset.from_tensor_slices((pad_embedded_array[:5], l_train[:5]))\n",
        "for row in numeric_dataset.take(3):\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JroXBQS7UIdT"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAqIp6WHkNLH"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', mode='max', verbose=1, save_best_only=True)\n",
        "x_train=pad_embedded_array\n",
        "# tf.data.Dataset.from_tensors(pad_embedded_array)\n",
        "y_train=l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbDiGBsg2JLM",
        "outputId": "2ce8d6a5-8efb-4734-8688-81b986439d26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pad_embedded_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEpHtXERsSN9",
        "outputId": "9accc32f-7c96-49f3-e4bb-6215585e229e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'> 1\n",
            "<class 'int'> 0\n",
            "<class 'int'> 1\n",
            "<class 'int'> 0\n",
            "<class 'int'> 0\n",
            "<class 'int'> 1\n",
            "<class 'int'> 0\n",
            "<class 'int'> 1\n",
            "<class 'int'> 0\n",
            "<class 'int'> 1\n"
          ]
        }
      ],
      "source": [
        "for i in y_train[:10]:\n",
        "  print(type(i),(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIbjgqiJue1q",
        "outputId": "84f6719c-a8d1-4688-9deb-06900205bbdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(x_train[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKLt6WRJ1zB4"
      },
      "outputs": [],
      "source": [
        "x_train_df=pd.DataFrame(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ot5rWw01_lk",
        "outputId": "4ae85df7-f80e-4cdb-8c63-8d170c8dc728"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(x_train_df[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAzaXGUC1Ce1",
        "outputId": "88dca940-1d32-490c-d23f-7426600aeae8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pd.DataFrame(x_train)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NaUEVcI2EC8",
        "outputId": "9e72fc49-4c38-4971-f2c2-8631121e351f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 1, 0, 0, 1, 0, 1, 0, 1]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(y_train.to_list()[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhuTnV4P1dnF",
        "outputId": "306d56db-69d0-42a6-fa80-6c5b7fcbc42d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(y_train[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "33pD13gjeIBY",
        "outputId": "7cd7813b-1d3c-427b-9d3f-6add663630cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-96681fbb929e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Train...\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;31m# batch_size=32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_embedded_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                     callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 991\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    992\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'float\\\\\\'>\"})\\', \\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'numpy.float32\\\\\\'>\"})\\'})'}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
          ]
        }
      ],
      "source": [
        "print( \"Train...\" )# batch_size=32\n",
        "history =lstm_model.fit(pad_embedded_array[:10], y_train.to_list()[:10], batch_size=batch_size, epochs=n_epoch,verbose=1,callbacks=[es, checkpoint])\n",
        "# history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\n",
        "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32p2R-AkYcm6"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UreTD_0VrQX7"
      },
      "source": [
        "# **TEST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhYe5oaxrQIH"
      },
      "source": [
        "**Prepare test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za1Mh2FusjYN",
        "outputId": "9c3bcbab-9b47-4e76-dd90-887651b979a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stanza/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n"
          ]
        }
      ],
      "source": [
        "# test_token_df['tokenized_sents'] = test_token_df.apply(lambda row: fa_nlp(row['comment']).sentences.words.text, axis=1)\n",
        "test_tokenized_array=[]\n",
        "for i in range(0,len(dev_df)):\n",
        "  comment=dev_df.iloc[i][\"comment\"]\n",
        "  tokenized_comment = fa_nlp(comment)\n",
        "  tokens_array=[]\n",
        "  for i,sent in enumerate(tokenized_comment.sentences):\n",
        "    for word in sent.words:\n",
        "      tokens_array.append(word.text)\n",
        "  test_tokenized_array.append(tokens_array)\n",
        "#word.text, word.lemma, word.pos, word.head, word.deprel))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAKJh43cosrq",
        "outputId": "030aba51-afab-4b26-bc97-36d4f8c14243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6300"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_tokenized_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-BEqALwouGA",
        "outputId": "29ace3d1-2036-45bc-e5e5-59f5124ea8c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['همه',\n",
              " 'ساندویچ\\u200cها',\n",
              " 'سرد',\n",
              " 'بود',\n",
              " 'متاسفانه',\n",
              " 'در',\n",
              " 'صورتی',\n",
              " 'که',\n",
              " 'فاصله',\n",
              " 'تا',\n",
              " 'رستوران',\n",
              " 'کمتر',\n",
              " 'از',\n",
              " '۵',\n",
              " 'دقیقه',\n",
              " 'است',\n",
              " '.']"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(test_tokenized_array[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zb2BlXOsrFL"
      },
      "outputs": [],
      "source": [
        "# pd.DataFrame(test_tokenized_array).to_csv('testtokens_df.csv')\n",
        "# #save tokens to array\n",
        "# import csv\n",
        "# with open('test_tokens_array.csv', 'w', newline='') as file:\n",
        "#     mywriter = csv.writer(file, delimiter=',')\n",
        "#     mywriter.writerows(test_tokenized_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVYoLxHZ16y3",
        "outputId": "f5822169-b6dd-4194-c950-ac702c6d218e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ],
      "source": [
        "# #read test array csv file\n",
        "# test_tokens_csv=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/testtokens_df.csv\",header=None)#test_tokens_array.csv\"\n",
        "# test_tokens_arr=test_tokens_csv.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8iIMQQB5bK3"
      },
      "outputs": [],
      "source": [
        "test_vectors_arr=[]\n",
        "for sent in test_tokens_arr:\n",
        "  vec_vocab=[model[word] for word in sent if word in vocabulary]\n",
        "  test_vectors_arr.append(vec_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_QhyY6Yrj4w",
        "outputId": "04ab64a1-9148-44da-82c0-1ba91a74446f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vectors_test_len = [len(x) for x in test_vectors_arr]\n",
        "# vectors_test_len=np.array(vectors_test_len)\n",
        "# max_vector_test_len=max(vectors_test_len)\n",
        "# max_vector_test_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V68Fivs05vvV"
      },
      "outputs": [],
      "source": [
        "max_vector_test_len=80\n",
        "#add padding vetor 0\n",
        "padding_vec=[0.0]*100\n",
        "padding_vec=np.array(padding_vec)\n",
        "pad_vec_test_array=[]\n",
        "for vector in test_vectors_arr:\n",
        "  if len(vector)<max_vector_test_len:\n",
        "    padding=[padding_vec]*(max_vector_test_len-len(vector))\n",
        "    vector=vector+padding\n",
        "  pad_vec_test_array.append(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9KrDqLU6WVk"
      },
      "outputs": [],
      "source": [
        "x_test=pad_vec_test_array\n",
        "y_test=dev_df[\"label_id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtQbe-34pcgg"
      },
      "outputs": [],
      "source": [
        "# evaluate the model\n",
        "scores = lstm_model.evaluate(x_test, y_test,batch_size, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxM6cODEUKL5"
      },
      "source": [
        "Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "XWOkJ0-xUgpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "x9LylZDKUj3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "7YeiE9ZhUqBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Confusion matrix**"
      ],
      "metadata": {
        "id": "nfeVqjRHUvfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_Y_pred = np.argmax(Y_pred, axis=1)\n",
        "new_Y_test = np.argmax(Y_test, axis=1)\n",
        "\n",
        "print(classification_report(new_Y_test, new_Y_pred))\n",
        "\n",
        "mpl.style.use('seaborn')\n",
        "\n",
        "conf_arr = np.zeros((num_classes, num_classes))\n",
        "\n",
        "for i in range(len(new_Y_pred)):\n",
        "        conf_arr[new_Y_pred[i]][new_Y_test[i]] += 1\n",
        "\n",
        "print(conf_arr)\n",
        "\n",
        "summ = conf_arr.sum()\n",
        "\n",
        "df_cm = pd.DataFrame(conf_arr, \n",
        "  index = unique_cat1,\n",
        "  columns = unique_cat1)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_aspect(1)\n",
        "\n",
        "cmap = sb.cubehelix_palette(light=1, as_cmap=True)\n",
        "\n",
        "res = sb.heatmap(df_cm, annot=True, vmin=0.0, vmax=np.max(conf_arr), fmt='.2f', cmap=cmap)\n",
        "\n",
        "res.invert_yaxis()\n",
        "\n",
        "plt.yticks([0.5,1.5,2.5,3.5,4.5,5.5], unique_cat1,va='center')\n",
        "\n",
        "print('\\n\\n')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "plt.savefig('confusion_matrix.png', dpi=700, bbox_inches='tight' )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4zgm6u_dUrq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accuracy**"
      ],
      "metadata": {
        "id": "4dHz1cO_VR_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrects = 0\n",
        "for i in range(len(new_Y_pred)):\n",
        "    if int(new_Y_pred[i]) is int(new_Y_test[i]):\n",
        "        corrects += 1\n",
        "        \n",
        "accuracy = float(corrects / len(new_Y_pred))*100\n",
        "print('Accuracy (using \"{}\" column): {} %'.format (column1, accuracy))\n",
        "\n",
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "id": "Jksc7f8yVtZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Precision**"
      ],
      "metadata": {
        "id": "wdOV7N_CV-Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Similar to the binary case, we can define precision for each of the classes\n",
        "precision = []\n",
        "#we append the precision for each class to the variable 'precision'\n",
        "for i in range(num_classes):\n",
        "  precision.append(conf_arr[i][i] / np.sum(conf_arr[i], axis = 0))\n",
        "\n",
        "print('Precisions per classes are : {}'.format(precision))\n",
        "\n",
        "macro_precision = 100 * np.sum(precision) / num_classes\n",
        "\n",
        "print('Macro averaged Precision is : {} %'.format(macro_precision))\n",
        "\n",
        "weighted_precision = 0\n",
        "total = 0\n",
        "for i in range(num_classes):\n",
        "  weighted_precision += np.sum(conf_arr, axis = 0)[i] * precision[i]\n",
        "  total += np.sum(conf_arr, axis = 0)[i]\n",
        "\n",
        "weighted_precision = 100 * weighted_precision / total\n",
        "print('Weighted Precision is : {} %'.format(weighted_precision))"
      ],
      "metadata": {
        "id": "YxBP2KelV9fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Recall**"
      ],
      "metadata": {
        "id": "VSBQDjqkWFUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Similar to the binary case, we can define recall for each of the classes\n",
        "recall = []\n",
        "#We append the recall for each class to the variable 'recall'\n",
        "for i in range(num_classes):\n",
        "  recall.append(conf_arr[i][i] / np.sum(conf_arr, axis = 0)[i])\n",
        "  \n",
        "print('Recalls per classes are : {}'.format(recall))\n",
        "\n",
        "macro_recall = 100 * np.sum(recall) / num_classes\n",
        "print('Macro averaged Recall is : {} %'.format(macro_recall))\n",
        "\n",
        "weighted_recall = 0\n",
        "for i in range(num_classes):\n",
        "  weighted_recall += np.sum(conf_arr, axis = 0)[i] * recall[i]\n",
        "\n",
        "weighted_recall = 100 * weighted_recall / total\n",
        "print('Weighted Recall is : {} %'.format(weighted_recall))  "
      ],
      "metadata": {
        "id": "Oj4adhLUWEEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **F1 score**"
      ],
      "metadata": {
        "id": "7IZN5vwgWJOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#F1-score is a function of precision and recall\n",
        "#we can now compute the per-class F1-score\n",
        "f1_score = []\n",
        "for i in range(num_classes):\n",
        "  f1_score.append( 2*( (recall[i]*precision[i]) / (recall[i]+precision[i])))\n",
        "\n",
        "print('F1-scores per classes are : {}'.format(f1_score))\n",
        "\n",
        "macro_f1 = 100 * np.sum(f1_score) / num_classes\n",
        "\n",
        "print('Macro averaged F1-score is : {} %'.format(macro_f1))\n",
        "\n",
        "weighted_f1 = 0\n",
        "for i in range(num_classes):\n",
        "  weighted_f1 += np.sum(conf_arr, axis = 0)[i] * f1_score[i]\n",
        "\n",
        "weighted_f1 = 100 * weighted_f1 / total\n",
        "print('Weighted F1-score is : {} %'.format(weighted_f1))  "
      ],
      "metadata": {
        "id": "jZ1xmrMBWRsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0KwhovBfPXyj",
        "7YeiE9ZhUqBo"
      ],
      "name": "Copy of Final_projet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}